{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acbed71c-d212-4e45-9af0-50cec7fe9ae4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import *\n",
    "import os\n",
    "\n",
    "write_mode = \"append\"\n",
    "\n",
    "last_successful_run = get_last_successful_run(BRONZE_INGESTION_LOGS) # type: ignore\n",
    "current_run_date =  datetime.date.today()\n",
    "\n",
    "\n",
    "if(last_successful_run == null):\n",
    "    read_start_date = datetime.datetime(2025 , 6 , 29)\n",
    "\n",
    "else:\n",
    "    read_start_date = last_successful_run.date()\n",
    "\n",
    "\n",
    "read_end_date = current_run_date.date()\n",
    "\n",
    "input_paths = []\n",
    "delta_days = (read_end_date - read_start_date).days\n",
    "\n",
    "\n",
    "if last_successful_run == null:\n",
    "    read_start_date = datetime.datetime(2025 , 6 , 29)\n",
    "    write_mode = \"overwrite\"\n",
    "\n",
    "else:\n",
    "    write_mode = \"append\"\n",
    "\n",
    "\n",
    "\n",
    "for i in (delta_days + 1):\n",
    "    \n",
    "    current_date = read_start_date + datetime.timedelta(days = i)\n",
    "    iterative_file_path = os.path.join(\n",
    "        S3_RAW_DATA_BASE_PATH,\n",
    "        f\"year={current_date.year}\",\n",
    "        f\"month={current_date.month:02d}\",\n",
    "        f\"day={current_date.day:02d}\"  \n",
    "    )\n",
    "    is_file_exists = dbutils.fs.ls(iterative_file_path)\n",
    "    if is_file_exists:\n",
    "        input_paths.append(iterative_file_path)\n",
    "    \n",
    "\n",
    "\n",
    "df = spark.read.format(\"csv\").option(\"header\" , \"true\").option(\"inferschema\" , \"false\").schema(definedSchema).path(input_paths)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "raw_to_bronze_ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
